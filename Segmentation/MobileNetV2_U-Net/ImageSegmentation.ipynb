{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageSegmentation.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjARzTgqqc_P",
        "colab_type": "text"
      },
      "source": [
        "# Image Segmentation\n",
        "Image Segmentation is a technique in which every pixel is given a class label. Thus, the task of image segmentation is to train a neural network to output a pixel-wise mask of the image. \n",
        "\n",
        "The dataset that we will use is the Oxford-IIIT Pet Dataset, created by Parkhi et al. Each pixel is maps to one of three categories:\n",
        "\n",
        "* Class 1 : Pixel belonging to the pet.\n",
        "* Class 2 : Pixel bordering the pet.\n",
        "* Class 3 : None of the above/ Surrounding pixel.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xi-LxIdWqbar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Installing necessary packages\n",
        "!pip install -q git+https://github.com/tensorflow/examples.git\n",
        "!pip install -q -U tfds-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Trg22udjyPRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "from IPython.display import clear_output\n",
        "from datetime import datetime\n",
        "\n",
        "tfds.disable_progress_bar()\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuaJfzlW0gdB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gloabl vars & hyper-params\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1000\n",
        "LABELS = 3\n",
        "TRAIN_ITERATIONS = 57\n",
        "VALID_ITERATIONS = 20\n",
        "EPOCHS = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W7BiBet1s1q",
        "colab_type": "text"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CIOLbG5TR3_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_results(images, save_fig=False):\n",
        "  fig = plt.figure() \n",
        "  fig.figsize=(15,15)\n",
        "  titles = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "  n_cols = len(images)\n",
        "  for i in range(n_cols):\n",
        "    plt.subplot(1, n_cols, i+1)\n",
        "    plt.title(titles[i])\n",
        "    plt.imshow(tf.keras.preprocessing.image.array_to_img(images[i]))\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "  if save_fig:\n",
        "    f_name = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    fig.savefig(f\"{f_name}.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udgdywdW1vSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize(image, mask):\n",
        "  \"\"\"\n",
        "  This function will normalize the image in the range of 0-1. For the sake of \n",
        "  convenience, will covert the mask from {1, 2, 3} into {0, 1, 2} by subtracting\n",
        "  1 from the original mask.\n",
        "  \"\"\"\n",
        "\n",
        "  normalized_image = tf.cast(image, tf.float32) / 255.0\n",
        "  mask -= 1\n",
        "  return normalized_image, mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tX1cK49A32mT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_image(image, height, width):\n",
        "  resized_image = tf.image.resize(image, [height, width], \n",
        "                                      method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return resized_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlA9NN6W3mWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def preprocess_image(image, mask, flip=True):\n",
        "  # Resizing image and mask to 128 X 128 X 3\n",
        "  resized_image = resize_image(image, 128, 128)\n",
        "  resized_mask = resize_image(mask, 128, 128)\n",
        "\n",
        "  # Normalizing image and updating mask values\n",
        "  processed_image, processed_mask = normalize(resized_image, resized_mask)\n",
        "\n",
        "  if flip and tf.random.uniform(()) > 0.5:\n",
        "    processed_image = tf.image.flip_left_right(processed_image)\n",
        "    processed_mask = tf.image.flip_left_right(processed_mask)\n",
        "\n",
        "  return processed_image, processed_mask"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDQ8jfhY7QrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_training_data(datapoint):\n",
        "  image = datapoint[\"image\"]\n",
        "  mask = datapoint[\"segmentation_mask\"]\n",
        "  return preprocess_image(image, mask)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDZF8qF55lAJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_test_data(datapoint):\n",
        "  image = datapoint[\"image\"]\n",
        "  mask = datapoint[\"segmentation_mask\"]\n",
        "  return preprocess_image(image, mask, False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzNtN_ZCWcNK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_mask(pred_mask):\n",
        "  pred_mask = tf.argmax(pred_mask, axis=-1)[..., tf.newaxis]\n",
        "  return pred_mask[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FAndEGnxbEjI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TestCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "  def __init__(self, test_dataset):\n",
        "    for images, real_masks in test_dataset.take(1):\n",
        "        self.test_img, self.test_mask = images[0], real_masks[0]\n",
        "    self.model = model\n",
        "\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    clear_output(wait=True)\n",
        "    predicted_mask = create_mask(self.model.predict(self.test_img[tf.newaxis, ...]))\n",
        "    show_results([self.test_img, self.test_mask, predicted_mask])\n",
        "    print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQtxMdwz1JiU",
        "colab_type": "text"
      },
      "source": [
        "## Preparing Input Pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdkUq2L21PDn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading Dataset\n",
        "dataset, info = tfds.load('oxford_iiit_pet:3.*.*', with_info=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "118zPnNN_0lr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating our training data\n",
        "train = dataset['train'].map(prepare_training_data, num_parallel_calls=\n",
        "                             tf.data.experimental.AUTOTUNE)\n",
        "train_dataset = train.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat().\\\n",
        "                            prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Creating our test data\n",
        "test = dataset['test'].map(prepare_test_data, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test_dataset = test.batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEeo_aTWGCy_",
        "colab_type": "text"
      },
      "source": [
        "## Model Definition\n",
        "\n",
        "The model being used here is a modified U-Net. In-order to learn robust features, and reduce the number of trainable parameters, we will use a pretrained model for the encoder. Thus, our encoder will be a pretrained MobileNetV2 model, whose intermediate outputs will be used, and the decoder will be the upsample block already implemented in TensorFlow Examples in the Pix2pix tutorial.\n",
        "\n",
        "**NOTE**: Any pretrained network can be used for encoder.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHnSurYoGCJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Masker(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, base_encoder_model, ):\n",
        "    super(Masker, self).__init__()\n",
        "    self.loss_cal = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True)\n",
        "    self._prepare_encoder(base_encoder_model)\n",
        "    self.decoder = [\n",
        "    pix2pix.upsample(512, 3),  # 4x4 -> 8x8\n",
        "    pix2pix.upsample(256, 3),  # 8x8 -> 16x16\n",
        "    pix2pix.upsample(128, 3),  # 16x16 -> 32x32\n",
        "    pix2pix.upsample(64, 3),   # 32x32 -> 64x64\n",
        "    ]\n",
        "\n",
        "    self.out = tf.keras.layers.Conv2DTranspose(LABELS, 3, \n",
        "                                    strides=2, \n",
        "                                    padding='same')  # 64x64 -> 128x128\n",
        "\n",
        "  def call(self, inputs):\n",
        "    # Running encoder\n",
        "    skips = self.encoder(inputs)\n",
        "    \n",
        "    inputs = skips[-1]\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # Running decoder with skip connections\n",
        "    for up, skip in zip(self.decoder, skips):\n",
        "      inputs = up(inputs)\n",
        "      inputs = tf.keras.layers.Concatenate()([inputs, skip])\n",
        "\n",
        "    return self.out(inputs)\n",
        "\n",
        "  def _prepare_encoder(self, base_encoder_model):\n",
        "    # Using the activations of the below layers for our encoder network\n",
        "    layer_names = [\n",
        "        'block_1_expand_relu',   # 64x64\n",
        "        'block_3_expand_relu',   # 32x32\n",
        "        'block_6_expand_relu',   # 16x16\n",
        "        'block_13_expand_relu',  # 8x8\n",
        "        'block_16_project',      # 4x4\n",
        "    ]\n",
        "    layers = [base_encoder_model.get_layer(name).output for name in layer_names]\n",
        "\n",
        "    # Creating the feature extraction model\n",
        "    self.encoder = tf.keras.Model(inputs=base_encoder_model.input, outputs=layers)\n",
        "    self.encoder.trainable = False\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XihEmX6gQouL",
        "colab_type": "text"
      },
      "source": [
        "## Let Training Begin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HAhi6ZfiKiEe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading MobileNetV2 model\n",
        "base_encoder_model = tf.keras.applications.MobileNetV2(input_shape=[128, 128, 3], include_top=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74C_lBSmQ0HK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading our segmentation model\n",
        "model = Masker(base_encoder_model)\n",
        "model.compile(optimizer ='adam',\n",
        "              loss = model.loss_cal,\n",
        "              metrics = ['accuracy'])\n",
        "\n",
        "callback_ob = TestCallback(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fs7jSRka_aQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_history = model.fit(train_dataset, epochs=EPOCHS,\n",
        "                          steps_per_epoch=TRAIN_ITERATIONS,\n",
        "                          validation_steps=VALID_ITERATIONS,\n",
        "                          validation_data=test_dataset,\n",
        "                          callbacks=[callback_ob])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60L383N4gLUJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Plotting performance\n",
        "loss = model_history.history['loss']\n",
        "val_loss = model_history.history['val_loss']\n",
        "epochs = range(EPOCHS)\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(epochs, loss, 'r', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'bo', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "plt.ylim([0, 1])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYzFFRnhno5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# More Predictions\n",
        "for test_imgs, test_masks in test_dataset.take(1):\n",
        "  for sample in range(5):\n",
        "    test_img = test_imgs[sample]\n",
        "    test_mask = test_masks[sample]\n",
        "    predicted_mask = create_mask(model.predict(test_img[tf.newaxis, ...]))\n",
        "    print(predicted_mask[0,0,0])\n",
        "    show_results([test_img, test_mask, predicted_mask], True)\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}