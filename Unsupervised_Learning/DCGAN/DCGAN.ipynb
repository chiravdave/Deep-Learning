{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQnnt7mxqURJ",
        "colab_type": "text"
      },
      "source": [
        "# Deep Convolutional Generative Adversarial Network\n",
        "\n",
        "DCGAN is a more stabilised version of GAN. It is based on convolutional architecture. Here, *two* models are trained simultaneously by an adversarial process. A generator (\"the artist\") learns to create images that look real, while a discriminator (\"the art critic\") learns to tell real images apart from fakes. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEw9-DiAp82u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fodrvmY0wSNg",
        "colab_type": "text"
      },
      "source": [
        "## Utility functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwLYPr7IwX2r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_images(images):\n",
        "  \"\"\"\n",
        "  This function will normalize the image in the range of [-1, 1]\n",
        "  \"\"\"\n",
        "\n",
        "  images = (images - 127.5) / 127.5\n",
        "  return images\n",
        "\n",
        "def deprocess_images(images):\n",
        "  images = (images * 127.5) + 127.5\n",
        "  return images\n",
        "\n",
        "def gen_noise(noise_shape):\n",
        "  return np.random.normal(size=noise_shape)\n",
        "\n",
        "def show_generated_images(images, save_fig: str=None):\n",
        "  \"\"\"\n",
        "  This function will show at max 4 images in a single row.\n",
        "  \"\"\"\n",
        "\n",
        "  n_images = images.shape[0]\n",
        "  n_rows = int(np.ceil(n_images/4))\n",
        "  for index in range(n_images):\n",
        "    plt.subplot(n_rows, 4, index+1)\n",
        "    denormalize_image = deprocess_images(images[index].numpy())\n",
        "    denormalize_image = denormalize_image.reshape(28, 28).astype(\"int32\")\n",
        "    plt.imshow(denormalize_image)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "  if save_fig:\n",
        "    plt.savefig(save_fig)\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "def train(generator, discriminator, real_images, noise):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    generated_images = generator(noise, training=True)\n",
        "    real_output = discriminator(real_images, training=True)\n",
        "    fake_output = discriminator(generated_images, training=True)\n",
        "    gen_loss = generator.generator_loss(fake_output)\n",
        "    disc_loss = discriminator.discriminator_loss(real_output, fake_output)\n",
        "\n",
        "  # calculating gradients\n",
        "  gen_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "  disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "  # adjusting weights\n",
        "  generator.generator_optimizer.apply_gradients(\n",
        "      zip(gen_gradients, generator.trainable_variables))\n",
        "  discriminator.discriminator_optimizer.apply_gradients(\n",
        "      zip(disc_gradients, discriminator.trainable_variables))\n",
        "  \n",
        "  return gen_loss, disc_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxMPlJ_EvhnG",
        "colab_type": "text"
      },
      "source": [
        "## Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxWtlszGwBX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading data\n",
        "(train_images, _), (test_images, _) = tf.keras.datasets.mnist.load_data()\n",
        "images = np.vstack((train_images, test_images))\n",
        "images = images.reshape(images.shape[0], 28, 28, 1).astype(\"float32\")\n",
        "normalized_images = preprocess_images(images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EPrVhXY0O6J",
        "colab_type": "text"
      },
      "source": [
        "## Models & Losses Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnY9wBPE0T9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Generator, self).__init__()\n",
        "    self.h1 = tf.keras.layers.Dense(7*7*256, use_bias=False)\n",
        "    self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "    self.a1 = tf.keras.layers.LeakyReLU()\n",
        "    self.reshape = tf.keras.layers.Reshape((7, 7, 256))\n",
        "    self.h2 = tf.keras.layers.Conv2DTranspose(128, 5, padding=\"same\", \n",
        "                                              use_bias=False)\n",
        "    self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "    self.a2 = tf.keras.layers.LeakyReLU()\n",
        "    self.h3 = tf.keras.layers.Conv2DTranspose(64, 5, padding=\"same\", strides=2, \n",
        "                                              use_bias=False)\n",
        "    self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "    self.a3 = tf.keras.layers.LeakyReLU()\n",
        "    self.gen_output = tf.keras.layers.Conv2DTranspose(1, 5, padding=\"same\", strides=2, \n",
        "                                              use_bias=False, activation=\"tanh\")\n",
        "    self.loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    self.generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    out_h1 = self.h1(inputs)\n",
        "    out_bn1 = self.bn1(out_h1)\n",
        "    out_a1 = self.a1(out_bn1)\n",
        "    out_reshape = self.reshape(out_a1)\n",
        "    out_h2 = self.h2(out_reshape)\n",
        "    out_bn2 = self.bn2(out_h2)\n",
        "    out_a2 = self.a2(out_bn2)\n",
        "    out_h3 = self.h3(out_a2)\n",
        "    out_bn3 = self.bn3(out_h3)\n",
        "    out_a3 = self.a3(out_bn3)\n",
        "    return self.gen_output(out_a3)\n",
        "\n",
        "  def generator_loss(self, fake_outputs):\n",
        "    return self.loss_fn(tf.ones_like(fake_outputs), fake_outputs)\n",
        "\n",
        "class Discriminator(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.h1 = tf.keras.layers.Conv2D(64, 5, padding=\"same\", strides=2)\n",
        "    self.a1 = tf.keras.layers.LeakyReLU()\n",
        "    self.h2 = tf.keras.layers.Conv2D(128, 5, padding=\"same\", strides=2)\n",
        "    self.a2 = tf.keras.layers.LeakyReLU()\n",
        "    self.flatten = tf.keras.layers.Flatten()\n",
        "    self.dense = tf.keras.layers.Dense(256)\n",
        "    self.dropout = tf.keras.layers.Dropout(0.4)\n",
        "    self.disc_output = tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "    self.loss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    self.discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    out_h1 = self.h1(inputs)\n",
        "    out_a1 = self.a1(out_h1)\n",
        "    out_h2 = self.h2(out_a1)\n",
        "    out_a2 = self.a2(out_h2)\n",
        "    out_flatten = self.flatten(out_a2)\n",
        "    out_dense = self.dense(out_flatten)\n",
        "    out_dropout = self.dropout(out_dense)\n",
        "    return self.disc_output(out_dropout)\n",
        "\n",
        "  def discriminator_loss(self, real_outputs, fake_outputs):\n",
        "    fake_loss = self.loss_fn(tf.zeros_like(fake_outputs), fake_outputs)\n",
        "    real_loss = self.loss_fn(tf.ones_like(real_outputs), real_outputs)\n",
        "    return fake_loss + real_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_209p61ZVQi",
        "colab_type": "text"
      },
      "source": [
        "## Training Starts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lRgv82noZZtP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Declaring hyper-parameters\n",
        "EPOCHS = 50\n",
        "NOISE_DIM = 100\n",
        "BATCH_SIZE = 256\n",
        "BUFFER_SIZE = 70000\n",
        "\n",
        "real_images = tf.data.Dataset.from_tensor_slices(normalized_images).\\\n",
        "              shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "# Initializing models\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()\n",
        "\n",
        "# Training starts\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "  for index, batch in enumerate(real_images):\n",
        "    noise = gen_noise((BATCH_SIZE, NOISE_DIM))\n",
        "    gen_loss, disc_loss = train(generator, discriminator, batch, noise)\n",
        "\n",
        "    if (index+1) % 100 == 0:\n",
        "      print(f\"Generator & Discriminator loss after {epoch} epoch and {256*(index+1)}\\\n",
        "      iterations is: {gen_loss:.4f}, {disc_loss:.4f}\")\n",
        "\n",
        "  noise = gen_noise((16, NOISE_DIM))\n",
        "  generated_images = generator(noise, training=False)\n",
        "  show_generated_images(generated_images, f\"/content/{epoch}.jpg\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}