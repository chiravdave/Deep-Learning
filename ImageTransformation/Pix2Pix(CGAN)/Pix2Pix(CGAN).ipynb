{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pix2Pix(CGAN).ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO2PsaelOUXg",
        "colab_type": "text"
      },
      "source": [
        "# Pix2Pix, aka CGAN (Conditional GAN)\n",
        "Pix2Pix is a type GAN use for image-to-image translation task. Here, an input image is translated into another image based on some condition. \n",
        "\n",
        "In this example, we will use the CMP Facade Database. We will use a preprocessed copy of this dataset provided by the authors of the above paper."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6lUJzVrOTgb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from os import path\n",
        "from datetime import datetime\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XF_GLOSZQpWy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downloading Tensorboard for visualization\n",
        "!pip install -q -U tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nq9RXAgzWELZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Global vars & hyper-params\n",
        "IMG_HEIGHT = 256\n",
        "IMG_WIDTH = 256\n",
        "URL = 'https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets/facades.tar.gz'\n",
        "\n",
        "BUFFER_SIZE = 400\n",
        "BATCH_SIZE = 1\n",
        "LAMBDA = 100\n",
        "EPOCHS = 150"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYvRFCWMRxEV",
        "colab_type": "text"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUYhqkrO7UPS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_results(input_img, real_img, gen_img, save_fig=False):\n",
        "  titles = [\"Input Image\", \"Real Image\", \"Generated Image\"]\n",
        "  images = [input_img[0], real_img[0], gen_img[0]]\n",
        "  fig = plt.figure() \n",
        "  fig.figsize=(15,15)\n",
        "  for i in range(3):\n",
        "    plt.subplot(1, 3, i+1)\n",
        "    plt.title(titles[i])\n",
        "    # Pixel values should be in the range 0-1 for float values\n",
        "    plt.imshow(images[i] * 0.5 + 0.5)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "  plt.show()\n",
        "  \n",
        "  if save_fig:\n",
        "    f_name = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    fig.savefig(f\"{f_name}.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xBHu6YjVRzbN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_img(img_path):\n",
        "  raw_contents = tf.io.read_file(img_path)\n",
        "  image = tf.image.decode_jpeg(raw_contents)\n",
        "  w = tf.shape(image)[1] // 2\n",
        "  real_img = tf.cast(image[:, :w, :], tf.float32)\n",
        "  input_img = tf.cast(image[:, w:, :], tf.float32)\n",
        "\n",
        "  return input_img, real_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDbHJ07HR0wB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_image(input_img, real_img, height, width):\n",
        "  resized_input_img = tf.image.resize(input_img, [height, width], \n",
        "                                      method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  resized_real_img = tf.image.resize(real_img, [height, width], \n",
        "                                      method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return resized_input_img, resized_real_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHMhRY9BTeYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_crop(input_img, real_img):\n",
        "  stacked_imgs = tf.stack([input_img, real_img], axis=0)\n",
        "  cropped_imgs = tf.image.random_crop(stacked_imgs, [2, IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "  \n",
        "  return cropped_imgs[0], cropped_imgs[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F16P9aRfU6KD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_img(input_img, real_img):\n",
        "  \"\"\"\n",
        "  Normalizing images in the range of [-1, 1]\n",
        "  \"\"\"\n",
        "\n",
        "  normalized_input_img = (input_img / 127.5) - 1\n",
        "  normalized_real_img = (real_img / 127.5) - 1\n",
        "\n",
        "  return normalized_input_img, normalized_real_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4HkM6OtXHe0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(input_img, real_img):\n",
        "  \"\"\"\n",
        "  This function will apply random jittering, cropping, mirroring and \n",
        "  normalization. \n",
        "  \"\"\"\n",
        "\n",
        "  # Normalizing images\n",
        "  normalize_input_img, normalized_real_img = normalize_img(input_img, real_img)\n",
        "\n",
        "  # Resizing images to 286 X 286 X 3\n",
        "  resized_input_img, resized_real_img = resize_image(normalize_input_img, \n",
        "                                      normalized_real_img, 286, 286)\n",
        "\n",
        "  # Cropping images to 256 X 256 X 3\n",
        "  processed_input_img, processed_real_img = get_random_crop(resized_input_img, \n",
        "                                                        resized_real_img)\n",
        "  \n",
        "  # Applying random mirroring\n",
        "  if tf.random.uniform([]) > 0.5:\n",
        "    processed_input_img = tf.image.flip_left_right(processed_input_img)\n",
        "    processed_real_img = tf.image.flip_left_right(processed_real_img)\n",
        "\n",
        "  return processed_input_img, processed_real_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2b7GgaMS4Tf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_training_data(img_path):\n",
        "  input_img, real_img = load_img(img_path)\n",
        "  return preprocess_image(input_img, real_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w5URdAiTjSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_test_data(img_path):\n",
        "  input_img, real_img = load_img(img_path)\n",
        "  resized_input_img, resized_real_img = resize_image(input_img, real_img, \n",
        "                                                   IMG_HEIGHT, IMG_WIDTH)\n",
        "  return normalize_img(resized_input_img, resized_real_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y8k5rZC4qeO0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_normal_init(mean, std):\n",
        "  return tf.random_normal_initializer(mean, std)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3h7G87-je17",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def upsample(filters, kernel_size, stride=2, pad=\"same\", apply_dropout=False):\n",
        "  mini_net = tf.keras.Sequential()\n",
        "  mini_net.add(\n",
        "      tf.keras.layers.Conv2DTranspose(filters, kernel_size, strides=stride, \n",
        "                              padding=pad, \n",
        "                              kernel_initializer=get_normal_init(0.0, 0.02), \n",
        "                              use_bias=False))\n",
        "  mini_net.add(tf.keras.layers.BatchNormalization())\n",
        "  \n",
        "  if apply_dropout:\n",
        "    mini_net.add(tf.keras.layers.Dropout(0.5))\n",
        "\n",
        "  mini_net.add(tf.keras.layers.ReLU())\n",
        "\n",
        "  return mini_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QpmijvHem5MR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def downsample(filters, kernel_size, stride=2, pad=\"same\", apply_bn=True):\n",
        "  mini_net = tf.keras.Sequential()\n",
        "  mini_net.add(\n",
        "      tf.keras.layers.Conv2D(filters, kernel_size, strides=stride, \n",
        "                              padding=pad, \n",
        "                              kernel_initializer=get_normal_init(0.0, 0.02), \n",
        "                              use_bias=False))  \n",
        "  if apply_bn:\n",
        "    mini_net.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "  mini_net.add(tf.keras.layers.LeakyReLU())\n",
        "\n",
        "  return mini_net"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2Z-RXk29xDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train(generator, discriminator, input_img, target_img, sum_writer, epoch):\n",
        "  with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "    gen_output = generator(input_img, training=True)\n",
        "    real_output = discriminator(tf.concat([input_img, target_img], axis=3), training=True)\n",
        "    fake_output = discriminator(tf.concat([input_img, gen_output], axis=3), training=True)\n",
        "\n",
        "    gen_total_loss, gen_gan_loss, gen_l1_loss = generator.loss(\n",
        "        fake_output, gen_output, target_img)\n",
        "    disc_loss = discriminator.loss(real_output, fake_output)\n",
        "\n",
        "  gen_gradients = gen_tape.gradient(gen_total_loss, generator.trainable_variables)\n",
        "  disc_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "  generator.optimizer.apply_gradients(zip(gen_gradients, generator.trainable_variables))\n",
        "  discriminator.optimizer.apply_gradients(zip(disc_gradients, discriminator.trainable_variables))\n",
        "\n",
        "  with sum_writer.as_default():\n",
        "    tf.summary.scalar('gen_total_loss', gen_total_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=epoch)\n",
        "    tf.summary.scalar('disc_loss', disc_loss, step=epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fbwdflvabfW",
        "colab_type": "text"
      },
      "source": [
        "## Preparing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpU9x3LBae_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_path = tf.keras.utils.get_file(\"facades.tar.gz\", URL, extract=True)\n",
        "DATASET_PATH = path.join(path.split(zip_path)[0], \"facades/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JzLLd_m9RA0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing training data\n",
        "training_data = tf.data.Dataset.list_files(path.join(DATASET_PATH+\"train/*.jpg\"))\n",
        "training_data = training_data.map(prepare_training_data, \n",
        "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "training_data = training_data.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "# Preparing test data\n",
        "test_data = tf.data.Dataset.list_files(path.join(DATASET_PATH+\"test/*.jpg\"))\n",
        "test_data = test_data.map(prepare_test_data, \n",
        "                                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "test_data = test_data.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8meF157nFWj",
        "colab_type": "text"
      },
      "source": [
        "## Models & Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGAC-hMznKd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Generator(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, out_channels):\n",
        "    super(Generator, self).__init__()\n",
        "    self.loss_cal = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    self.optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    self.down_stack = [\n",
        "          downsample(64, 4, apply_bn=False), # (BATCH_SIZE, 128, 128, 64)\n",
        "          downsample(128, 4), # (BATCH_SIZE, 64, 64, 128)\n",
        "          downsample(256, 4), # (BATCH_SIZE, 32, 32, 256)\n",
        "          downsample(512, 4), # (BATCH_SIZE, 16, 16, 512)\n",
        "          downsample(512, 4), # (BATCH_SIZE, 8, 8, 512)\n",
        "          downsample(512, 4), # (BATCH_SIZE, 4, 4, 512)\n",
        "          downsample(512, 4), # (BATCH_SIZE, 2, 2, 512)\n",
        "          downsample(512, 4) # (BATCH_SIZE, 1, 1, 512)\n",
        "    ]\n",
        "\n",
        "    self.up_stack = [\n",
        "          upsample(512, 4, apply_dropout=True), # (BATCH_SIZE, 2, 2, 512)\n",
        "          upsample(512, 4, apply_dropout=True), # (BATCH_SIZE, 4, 4, 512)\n",
        "          upsample(512, 4, apply_dropout=True), # (BATCH_SIZE, 8, 8, 512)\n",
        "          upsample(512, 4), # (BATCH_SIZE, 16, 16, 512)\n",
        "          upsample(256, 4), # (BATCH_SIZE, 32, 32, 256)\n",
        "          upsample(128, 4), # (BATCH_SIZE, 64, 64, 128)\n",
        "          upsample(64, 4) # (BATCH_SIZE, 128, 128, 64)\n",
        "    ]\n",
        "\n",
        "    self.out = tf.keras.layers.Conv2DTranspose(out_channels, 4,\n",
        "                                  strides=2,\n",
        "                                  padding='same',\n",
        "                                  kernel_initializer=get_normal_init(0.0, 0.02),\n",
        "                                  activation='tanh') # (BATCH_SIZE, 256, 256, 3)\n",
        "    \n",
        "  def call(self, inputs):\n",
        "    skips = []\n",
        "    # Encoder part\n",
        "    for down in self.down_stack:\n",
        "      inputs = down(inputs)\n",
        "      skips.append(inputs)\n",
        "\n",
        "    skips = reversed(skips[:-1])\n",
        "\n",
        "    # Decoder part with skip connections\n",
        "    for up, skip in zip(self.up_stack, skips):\n",
        "      inputs = up(inputs)\n",
        "      inputs = tf.keras.layers.Concatenate()([inputs, skip])\n",
        "\n",
        "    return self.out(inputs)\n",
        "\n",
        "  def loss(self, fake_out, gen_img, target_img):\n",
        "    # Typical GAN loss\n",
        "    gan_loss = self.loss_cal(tf.ones_like(fake_out), fake_out)\n",
        "    # Image construction loss\n",
        "    l1_loss = tf.reduce_mean(tf.abs(target_img - gen_img))\n",
        "    total_loss = gan_loss + (LAMBDA * l1_loss)\n",
        "\n",
        "    return total_loss, gan_loss, l1_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s99ztvDntnVk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.loss_cal = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "    self.optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "    self.down_stack = [\n",
        "          downsample(64, 4, apply_bn=False), # (BATCH_SIZE, 128, 128, 64)\n",
        "          downsample(128, 4), # (BATCH_SIZE, 64, 64, 128)\n",
        "          downsample(256, 4), # (BATCH_SIZE, 32, 32, 256)\n",
        "          tf.keras.layers.ZeroPadding2D(), # (BATCH_SIZE, 34, 34, 256)\n",
        "          downsample(512, 4, 1, \"valid\"), # (BATCH_SIZE, 31, 31, 512)\n",
        "          tf.keras.layers.ZeroPadding2D(), # (BATCH_SIZE, 33, 33, 256)\n",
        "    ]\n",
        "\n",
        "    self.out = tf.keras.layers.Conv2D(1, 4, \n",
        "                                  strides=1, \n",
        "                                  kernel_initializer=get_normal_init(0.0, 0.02)\n",
        "                                  ) # (BATCH_SIZE, 30, 30, 1)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    for down in self.down_stack:\n",
        "      inputs = down(inputs)\n",
        "\n",
        "    return self.out(inputs)\n",
        "\n",
        "  def loss(self, real_out, fake_out):\n",
        "    real_loss = self.loss_cal(tf.ones_like(fake_out), real_out)\n",
        "    fake_loss = self.loss_cal(tf.zeros_like(fake_out), fake_out)\n",
        "    return real_loss + fake_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcnrfa3a5jW-",
        "colab_type": "text"
      },
      "source": [
        "## Let Training Begin"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiruyE_A4lj-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator = Generator(3)\n",
        "discriminator = Discriminator()\n",
        "\n",
        "log_dir = \"logs/\"\n",
        "summary_writer = tf.summary.create_file_writer(\n",
        "    log_dir + \"fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {log_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGNrMHnuAuNO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  print(f\"Running epoch: {epoch}\")\n",
        "  train_data = training_data.as_numpy_iterator()\n",
        "  for _ in tqdm(range(BUFFER_SIZE)):\n",
        "    input_img, target_img = next(train_data)\n",
        "    train(generator, discriminator, input_img, target_img, summary_writer, epoch)\n",
        "\n",
        "  if (epoch+1) % 20 == 0:\n",
        "    for input_img, target_img in test_data.take(1):\n",
        "      gen_img = generator(input_img, training=True)\n",
        "      show_results(input_img, target_img, gen_img, True)\n",
        "      generator.save(f\"gen_{epoch+1}\")\n",
        "      discriminator.save(f\"disc_{epoch+1}\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}