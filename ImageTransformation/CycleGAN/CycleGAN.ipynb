{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "31vma7efXMTZ",
        "colab_type": "text"
      },
      "source": [
        "# CycleGAN\n",
        "CycleGAN is a method that can capture the characteristics of one image domain and figure out how these characteristics could be translated into another image domain, all in the absence of any paired training examples. It uses a cycle consistency loss to enable training without the need for paired data. In other words, it can translate from one domain to another without a one-to-one mapping between the source and target domain"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-iWGdCca1Ol",
        "colab_type": "code",
        "outputId": "53775050-3f10-4631-a844-36480c01b7b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\"\"\"\n",
        "Installing tensorflow_examples package which will enable importing of \n",
        "Generator & Discriminator\n",
        "\"\"\"\n",
        "\n",
        "!pip install -q git+https://github.com/tensorflow/examples.git\n",
        "!pip install -q -U tensorboard"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XUGbExtQV0qA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from datetime import datetime\n",
        "from tensorflow_examples.models.pix2pix import pix2pix\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-K_JBX9cwY0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Gloabl vars & hyper-params\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "BUFFER_SIZE = 1000\n",
        "BATCH_SIZE = 1\n",
        "IMG_WIDTH = 256\n",
        "IMG_HEIGHT = 256\n",
        "OUTPUT_CHANNELS = 3\n",
        "LAMBDA = 100\n",
        "EPOCHS = 50"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2qrRJkOYd66O",
        "colab_type": "text"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yLi1HMj6U0z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_results(horse, gen_zebra, zebra, gen_horse, save_fig=False):\n",
        "  titles = [\"Horse\", \"To Zebra\", \"Zebra\", \"To Horse\"]\n",
        "  images = [horse, gen_zebra, zebra, gen_horse]\n",
        "  fig = plt.figure() \n",
        "  fig.figsize=(10,10)\n",
        "  contrast = 8\n",
        "  for i in range(4):\n",
        "    plt.subplot(2, 2, i+1)\n",
        "    plt.title(titles[i])\n",
        "    # Pixel values should be in the range 0-1 for float values\n",
        "    if (i+1) % 2 == 0:\n",
        "      plt.imshow(images[i] * 0.5 * contrast + 0.5)\n",
        "    else:\n",
        "      plt.imshow(images[i] * 0.5 + 0.5)\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "  plt.show()\n",
        "  \n",
        "  if save_fig:\n",
        "    f_name = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "    fig.savefig(f\"{f_name}.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yett3ZdggDoX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def resize_image(image, height, width):\n",
        "  resized_image = tf.image.resize(image, [height, width], \n",
        "                                      method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "  return resized_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NemmUtIId7RC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_crop(image):\n",
        "  cropped_img = tf.image.random_crop(image, [IMG_HEIGHT, IMG_WIDTH, 3])\n",
        "  \n",
        "  return cropped_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IuLapzVqe2Ru",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def normalize_img(image):\n",
        "  \"\"\"\n",
        "  Normalizing image in the range of [-1, 1]\n",
        "  \"\"\"\n",
        "\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  normalized_image = (image / 127.5) - 1\n",
        "\n",
        "  return normalized_image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mkbNeNszfrxG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_image(image):\n",
        "  \"\"\"\n",
        "  This function will apply random jittering, cropping, mirroring and \n",
        "  normalization. \n",
        "  \"\"\"\n",
        "\n",
        "  # Normalizing images\n",
        "  normalized_img = normalize_img(image)\n",
        "\n",
        "  # Resizing images to 286 X 286 X 3\n",
        "  resized_img = resize_image(normalized_img, 286, 286)\n",
        "\n",
        "  # Cropping images to 256 X 256 X 3\n",
        "  cropped_img = get_random_crop(resized_img)\n",
        "  \n",
        "  # Applying random mirroring\n",
        "  processed_img = tf.image.flip_left_right(cropped_img)\n",
        "\n",
        "  return processed_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bYucBnNOhp34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_training_data(image, label):\n",
        "  return preprocess_image(image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9_X_n2CiOIg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_test_data(image, label):\n",
        "  resized_img = resize_image(image, IMG_HEIGHT, IMG_WIDTH)\n",
        "  \n",
        "  return normalize_img(resized_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWI0Q2IvevVL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discriminator_loss(real_out, fake_out, loss_cal):\n",
        "  real_loss = loss_cal(tf.ones_like(real_out), real_out)\n",
        "  fake_loss = loss_cal(tf.zeros_like(fake_out), fake_out)\n",
        "\n",
        "  return (real_loss + fake_loss) * 0.5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cdzHy1xfWNa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generator_loss(fake_out, loss_cal):\n",
        "  return loss_cal(tf.ones_like(fake_out), fake_out)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRRa9JVs0Dw1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cycle_loss(real_img, cycled_img):\n",
        "  loss = tf.reduce_mean(tf.abs(real_img - cycled_img))\n",
        "\n",
        "  return loss * LAMBDA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XaUXxVJh0T4g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def identity_loss(real_img, same_img):\n",
        "  loss = tf.reduce_mean(tf.abs(real_img - same_img))\n",
        "\n",
        "  return loss * 0.5 * LAMBDA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_OZ_H4NyB8A",
        "colab_type": "text"
      },
      "source": [
        "### Losses:\n",
        "\n",
        "\n",
        "* GAN Loss: This is a typical GAN loss. \n",
        "* Cycle Loss: This is a loss that helps both the generator to generate meaningful mapping.\n",
        "* Identity Loss: This loss is helpful when we want to preserve some color composition between input and output. Sometimes we may need to keep some things as it is as which are common to both the input and the output images.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AZ5p3VNnty2E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function\n",
        "def train(real_x, real_y, gen_g, gen_f, desc_x, desc_y, gen_g_opt, gen_f_opt, \n",
        "          desc_x_opt, desc_y_opt, loss_cal, sum_writer, epoch):\n",
        "  with tf.GradientTape(persistent=True) as tape:\n",
        "    # Forward cycle: X -> Y -> X'\n",
        "    fake_y = gen_g(real_x, training=True)\n",
        "    cycled_x = gen_f(fake_y, training=True)\n",
        "\n",
        "    # Backward cycle: Y -> X -> Y'\n",
        "    fake_x = gen_f(real_y, training=True)\n",
        "    cycled_y = gen_g(fake_x, training=True)\n",
        "\n",
        "    # Identity check (no changing)\n",
        "    same_y = gen_g(real_y, training=True)\n",
        "    same_x = gen_f(real_x, training=True)\n",
        "\n",
        "    # Forward passes for discriminator network X\n",
        "    disc_x_real_out = desc_x(real_x, training=True)\n",
        "    disc_x_fake_out = desc_x(fake_x, training=True)\n",
        "\n",
        "    # Forward passes for discriminator network Y\n",
        "    disc_y_real_out = desc_y(real_y, training=True)\n",
        "    disc_y_fake_out = desc_y(fake_y, training=True)\n",
        "\n",
        "    # GAN loss\n",
        "    gen_g_loss = generator_loss(disc_y_fake_out, loss_cal)\n",
        "    gen_f_loss = generator_loss(disc_x_fake_out, loss_cal)\n",
        "\n",
        "    desc_x_loss = discriminator_loss(disc_x_real_out, disc_x_fake_out, loss_cal)\n",
        "    desc_y_loss = discriminator_loss(disc_y_real_out, disc_y_fake_out, loss_cal)\n",
        "\n",
        "    # Cycle loss\n",
        "    total_cycle_loss = cycle_loss(real_x, cycled_x) + cycle_loss(real_y, cycled_y)\n",
        "\n",
        "    # Identity loss\n",
        "    gen_g_identity_loss = identity_loss(real_y, same_y)\n",
        "    gen_f_identity_loss = identity_loss(real_x, same_x)\n",
        "\n",
        "    # Total generator losses\n",
        "    total_gen_g_loss = gen_g_loss + total_cycle_loss + gen_g_identity_loss\n",
        "    total_gen_f_loss = gen_f_loss + total_cycle_loss + gen_f_identity_loss\n",
        "\n",
        "  # Calculating gradients\n",
        "  gen_g_gradients = tape.gradient(total_gen_g_loss, gen_g.trainable_variables)\n",
        "  gen_f_gradients = tape.gradient(total_gen_f_loss, gen_f.trainable_variables)\n",
        "\n",
        "  desc_x_gradients = tape.gradient(desc_x_loss, desc_x.trainable_variables)\n",
        "  desc_y_gradients = tape.gradient(desc_y_loss, desc_y.trainable_variables)\n",
        "\n",
        "  # Apply gradients to optimize weights\n",
        "  gen_g_opt.apply_gradients(zip(gen_g_gradients, gen_g.trainable_variables))\n",
        "  gen_f_opt.apply_gradients(zip(gen_f_gradients, gen_f.trainable_variables))\n",
        "\n",
        "  desc_x_opt.apply_gradients(zip(desc_x_gradients, desc_x.trainable_variables))\n",
        "  desc_y_opt.apply_gradients(zip(desc_y_gradients, desc_y.trainable_variables))\n",
        "\n",
        "  with sum_writer.as_default():\n",
        "    tf.summary.scalar('gen_g_loss', total_gen_g_loss, step=epoch)\n",
        "    tf.summary.scalar('gen_f_loss', total_gen_f_loss, step=epoch)\n",
        "    tf.summary.scalar('desc_x_loss', desc_x_loss, step=epoch)\n",
        "    tf.summary.scalar('disc_y_loss', desc_y_loss, step=epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIlmGLNni5IR",
        "colab_type": "text"
      },
      "source": [
        "## Preparing Input Pipeline\n",
        "In this tutorial we will train a model that will learn to translate from images of horses, to images of zebras."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_njdsKkjTVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset, metadata = tfds.load('cycle_gan/horse2zebra',\n",
        "                              with_info=True, as_supervised=True)\n",
        "\n",
        "train_horses, train_zebras = dataset['trainA'], dataset['trainB']\n",
        "test_horses, test_zebras = dataset['testA'], dataset['testB']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk9KzJ6aj8n1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_horses = train_horses.map(\n",
        "    prepare_training_data, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
        "    BUFFER_SIZE).batch(1)\n",
        "\n",
        "train_zebras = train_zebras.map(\n",
        "    prepare_training_data, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
        "    BUFFER_SIZE).batch(1)\n",
        "\n",
        "test_horses = test_horses.map(\n",
        "    prepare_test_data, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
        "    BUFFER_SIZE).batch(1)\n",
        "\n",
        "test_zebras = test_zebras.map(\n",
        "    prepare_test_data, num_parallel_calls=AUTOTUNE).cache().shuffle(\n",
        "    BUFFER_SIZE).batch(1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDEyn0ftpIVh",
        "colab_type": "text"
      },
      "source": [
        "## Let Training Begin\n",
        "There are 2 generators (G and F) and 2 discriminators (X and Y) being trained here. \n",
        "\n",
        "* Generator G learns to transform image X to image Y.  (G: X -> Y)\n",
        "* Generator F learns to transform image Y to image X.  (F: Y -> X)\n",
        "* Discriminator D_X learns to differentiate between image X and generated image X (F(Y)).\n",
        "* Discriminator D_Y learns to differentiate between image Y and generated image Y (G(X))."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXrphAaHpGg0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
        "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm')\n",
        "\n",
        "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False)\n",
        "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnsuWCpP0ho0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "gen_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "\n",
        "disc_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
        "disc_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1h8z1vea53cG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing tensorboad for visualization\n",
        "log_dir = \"logs/\"\n",
        "summary_writer = tf.summary.create_file_writer(\n",
        "    log_dir + \"fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {log_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPG1555O6Dz7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zipped_dataset = tf.data.Dataset.zip((train_horses, train_zebras))\n",
        "loss_cal = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "for epoch in range(EPOCHS):\n",
        "  for horse_img, zebra_img in zipped_dataset:\n",
        "    train(horse_img, zebra_img, generator_g, generator_f, discriminator_x, discriminator_y, gen_g_optimizer, gen_f_optimizer, \n",
        "          disc_x_optimizer, disc_y_optimizer, loss_cal, summary_writer, epoch)\n",
        "  \n",
        "  if (epoch+1) % 10 == 0:\n",
        "    for horse, zebra in zip(test_horses.take(1), test_zebras.take(1)):\n",
        "      gen_zebra = generator_g(horse)\n",
        "      gen_horse = generator_g(zebra)\n",
        "      show_results(horse[0], gen_zebra[0], zebra[0], gen_horse[0], save_fig=True)\n",
        "\n",
        "  print(f\"Epoch {epoch} done.\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}