{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralStyleTransfer.ipynb",
      "provenance": [],
      "private_outputs": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucPG-lWkYq5n",
        "colab_type": "text"
      },
      "source": [
        "# Neural Style Transfer\n",
        "\n",
        "> Neural style transfer is an optimization technique where two images—a *content* image and a *style reference* image (such as an artwork by a famous painter)—are blend together to create an output image which would look like the content image, but “painted” in the style of the style reference image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZxdRB0mY2AW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSQpUMuu6zHR",
        "colab_type": "text"
      },
      "source": [
        "# Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ur0MRllgnXXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_img(img, title):\n",
        "  if len(img.shape) > 3:\n",
        "    img = tf.squeeze(img, axis=0)\n",
        "  \n",
        "  plt.title(title)\n",
        "  plt.imshow(img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ8oJcZ1lhQ2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_tensor_as_img(tensor):\n",
        "  img = tensor.numpy()\n",
        "  show_img(img, \"Generated Image\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJ1d_gFgQ-yT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_img(img, img_path):\n",
        "  if len(img.shape) > 3:\n",
        "    img = tf.squeeze(img, axis=0)\n",
        "  img *= 255.0 \n",
        "  tf.keras.preprocessing.image.save_img(img_path, img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRkCn0hfX0fh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clip_img(img, min_val=0.0, max_val=1.0):\n",
        "  return tf.clip_by_value(img, min_val, max_val, name=\"clipping_img\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3glfg9Ijv96k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scale_img(img, max_size=512):\n",
        "  shape = tf.cast(img.shape[:-1], dtype=tf.float32)\n",
        "  max_dim = max(shape)\n",
        "  scale = tf.constant(max_size / max_dim, dtype=tf.float32)\n",
        "  new_shape = tf.cast(shape * scale, dtype=tf.int32)\n",
        "  resized_img = tf.image.resize(img, new_shape, name=\"resizing_img\")\n",
        "  return resized_img[tf.newaxis, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEHcwj8RKhTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_img(img_loc, img_name=\"input_img\"):\n",
        "  raw_img = tf.io.read_file(img_loc)\n",
        "  img = tf.io.decode_image(raw_img, channels=3, dtype=tf.float32, \n",
        "                           name= img_name)\n",
        "  scaled_img = scale_img(img)\n",
        "  return scaled_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoJRBh48YAG_",
        "colab_type": "text"
      },
      "source": [
        "# Model Definition & Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noQuB7aOOWYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gram_matrix(feature_map):\n",
        "  b, h, w, c = feature_map.shape\n",
        "  reshaped_map = tf.reshape(feature_map, [w * h, c])\n",
        "  normalization_factor = tf.cast(h * w * c, dtype=tf.float32)\n",
        "  gram_matrix = tf.linalg.einsum('bijc,bijd->bcd', feature_map, feature_map, \n",
        "                                 name=\"gram_matrix\")\n",
        "  return gram_matrix / normalization_factor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IokJTt2RbDWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def content_style_loss(generated_outputs, content_targets, style_targets, \n",
        "                       content_weight, style_weight):\n",
        "  generated_content_outputs = generated_outputs[\"content_map\"]\n",
        "  generated_style_outputs = generated_outputs[\"style_map\"]\n",
        "  content_loss = [tf.reduce_mean((content_targets[layer_name] - generated_content_outputs[layer_name])**2)\n",
        "                                 for layer_name in generated_content_outputs.keys()]\n",
        "  content_loss = tf.reduce_mean(content_loss, name=\"content_loss\")\n",
        "  \n",
        "  style_loss = [tf.reduce_mean((style_targets[layer_name] - generated_style_outputs[layer_name])**2)\n",
        "                                 for layer_name in generated_style_outputs.keys()]\n",
        "  style_loss = tf.reduce_mean(style_loss, name=\"style_loss\")\n",
        "\n",
        "  total_loss = content_weight * content_loss + style_weight * style_loss\n",
        "  return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZBoYNalgAQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(img, model, optimizer, content_targets, style_targets, \n",
        "               content_weight, style_weight):\n",
        "  with tf.GradientTape() as tape:\n",
        "    generated_outputs = model(img)\n",
        "    loss = content_style_loss(generated_outputs, content_targets, style_targets,\n",
        "                              content_weight, style_weight)\n",
        "\n",
        "  gradients = tape.gradient(loss, img)\n",
        "  optimizer.apply_gradients([(gradients, img)])\n",
        "  img.assign(clip_img(img))\n",
        "  return loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wQfwozN6ol0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_custom_vgg_model(layer_names):\n",
        "  # Loading pre-trained VGG19 network\n",
        "  vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
        "  vgg.trainable = False\n",
        "  output_layers = [vgg.get_layer(name).output for name in layer_names]\n",
        "  model = tf.keras.Model(vgg.input, output_layers)\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_L-9C8m5ahI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NSTModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, content_layers, style_layers):\n",
        "    super(NSTModel, self).__init__()\n",
        "    self.custom_vgg = get_custom_vgg_model(content_layers + style_layers)\n",
        "    self.preprocessor = tf.keras.applications.vgg19.preprocess_input\n",
        "    self.content_layers = content_layers\n",
        "    self.style_layers = style_layers\n",
        "    self.n_content_layers = len(content_layers)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    inputs = inputs * 255.0\n",
        "    preprocessed_inputs = self.preprocessor(inputs)\n",
        "    outputs = self.custom_vgg(preprocessed_inputs)\n",
        "    content_outputs, style_outputs = outputs[:self.n_content_layers], \\\n",
        "                                      outputs[self.n_content_layers:]\n",
        "    style_corr_values = [gram_matrix(feature_map) \n",
        "                        for feature_map in style_outputs]\n",
        "    content_map = {layer_name: layer_output for layer_name, layer_output \n",
        "                   in zip(self.content_layers, content_outputs)}\n",
        "    style_map = {layer_name: layer_output for layer_name, layer_output\n",
        "                 in zip(self.style_layers, style_corr_values)}\n",
        "    return {\"content_map\": content_map, \"style_map\": style_map}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZT-HfJdYTQ7",
        "colab_type": "text"
      },
      "source": [
        "# Content & Style Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5RURqZoz7bA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choosing our content layers\n",
        "content_layers = [\"block5_conv2\"]\n",
        "\n",
        "# Choosing out style layers\n",
        "style_layers = [\"block1_conv1\", \"block2_conv1\", \"block3_conv1\", \"block4_conv1\", \n",
        "                \"block5_conv1\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2qHCEgdWYvO",
        "colab_type": "text"
      },
      "source": [
        "# Style Transfer Begins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THq_MyGqWN2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating object for our model\n",
        "model = NSTModel(content_layers, style_layers)\n",
        "\n",
        "# Creating our model optimzer\n",
        "adam_opt = tf.optimizers.Adam(learning_rate=0.001, beta_1=0.99, epsilon=1e-1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OVf7dvXjE6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading our content image\n",
        "content_img = prepare_img(\"/content/bhai.jpeg\")\n",
        "\n",
        "# Preparing our target values\n",
        "content_targets = model(content_img)[\"content_map\"]\n",
        "\n",
        "# Preparing our output image\n",
        "output_img = tf.Variable(content_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XkQZD_FYpgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading our style image\n",
        "style_img = prepare_img(\"/content/style1.jpg\")\n",
        "\n",
        "# Preparing our target values\n",
        "style_targets = model(style_img)[\"style_map\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13_ca1SCr3Ai",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.subplot(1, 2, 1)\n",
        "show_img(content_img, \"Content Image\")\n",
        "plt.subplot(1, 2, 2)\n",
        "show_img(style_img, \"Style Image\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVI6lRcOZ5z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining our hyper-parameters\n",
        "content_weight = 1e-4\n",
        "style_weight = 1e-3\n",
        "n_iter = 300\n",
        "\n",
        "# Running gradient descent on output image\n",
        "for cur_iter in range(1, n_iter+1):\n",
        "  loss = train_step(output_img, model, adam_opt, content_targets, style_targets,\n",
        "                    content_weight, style_weight)\n",
        "  if cur_iter % 50 == 0:\n",
        "    print(\"Loss after {} iteration is: {:.4f}\".format(cur_iter, loss))\n",
        "    save_img(output_img.numpy(), \"/content/gen_img_{}.jpeg\".format(cur_iter))\n",
        "\n",
        "show_tensor_as_img(output_img)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}