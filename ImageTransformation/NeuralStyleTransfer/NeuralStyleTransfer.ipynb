{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NeuralStyleTransfer.ipynb",
      "provenance": [],
      "private_outputs": true,
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ucPG-lWkYq5n",
        "colab_type": "text"
      },
      "source": [
        "# Neural Style Transfer\n",
        "\n",
        "> Neural style transfer is an optimization technique where two images—a *content* image and a *style reference* image (such as an artwork by a famous painter)—are blend together to create an output image which would look like the content image, but “painted” in the style of the style reference image.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZxdRB0mY2AW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing libraries\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from datetime import datetime\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdggKNP36XUi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Hyper-parameters\n",
        "CONTENT_WEIGHT = 1e3\n",
        "STYLE_WEIGHT = 1e1\n",
        "EPOCHS = 1000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSQpUMuu6zHR",
        "colab_type": "text"
      },
      "source": [
        "# Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZGZrX2AuQe2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def show_result(image, save_fig=False):\n",
        "  if len(image.shape) > 3:\n",
        "    image = tf.squeeze(image, axis=0)\n",
        "  \n",
        "  fig = plt.figure() \n",
        "  fig.figsize=(15,15)\n",
        "  plt.title(\"Styled Image\")\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(image)\n",
        "  \n",
        "  if save_fig:\n",
        "    fig.savefig(f\"styled_image_{datetime.now()}.png\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRkCn0hfX0fh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clip_img(img, min_val=0.0, max_val=1.0):\n",
        "  return tf.clip_by_value(img, min_val, max_val, name=\"clipping_img\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3glfg9Ijv96k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def scale_img(img, max_size=512):\n",
        "  shape = tf.cast(img.shape[:-1], dtype=tf.float32)\n",
        "  max_dim = max(shape)\n",
        "  scale = tf.constant(max_size / max_dim, dtype=tf.float32)\n",
        "  new_shape = tf.cast(shape * scale, dtype=tf.int32)\n",
        "  resized_img = tf.image.resize(img, new_shape, name=\"resizing_img\")\n",
        "  return resized_img[tf.newaxis, ...]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEHcwj8RKhTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_img(img_loc, img_name=\"input_img\"):\n",
        "  raw_img = tf.io.read_file(img_loc)\n",
        "  img = tf.io.decode_image(raw_img, channels=3, dtype=tf.float32, \n",
        "                           name= img_name)\n",
        "  scaled_img = scale_img(img)\n",
        "  return scaled_img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Tumpj0fxk2H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_model(layer_names):\n",
        "    # Loading pre-trained VGG19 network\n",
        "    vgg = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
        "    vgg.trainable = False\n",
        "    output_layers = [vgg.get_layer(name).output for name in layer_names]\n",
        "    return tf.keras.Model(vgg.input, output_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YoJRBh48YAG_",
        "colab_type": "text"
      },
      "source": [
        "# Model Definition & Losses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IokJTt2RbDWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loss_cal(outputs, content_targets, style_targets):\n",
        "  content_outputs = outputs[\"content_map\"]\n",
        "  style_outputs = outputs[\"style_map\"]\n",
        "  \n",
        "  content_loss = [tf.reduce_mean((content_targets[layer_name] - content_outputs[layer_name])**2)\n",
        "                                 for layer_name in content_outputs.keys()]\n",
        "  content_loss = tf.reduce_mean(content_loss, name=\"content_loss\")\n",
        "  \n",
        "  style_loss = [tf.reduce_mean((style_targets[layer_name] - style_outputs[layer_name])**2)\n",
        "                                 for layer_name in style_outputs.keys()]\n",
        "  style_loss = tf.reduce_mean(style_loss, name=\"style_loss\")\n",
        "\n",
        "  total_loss = CONTENT_WEIGHT * content_loss + STYLE_WEIGHT * style_loss\n",
        "  return total_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZBoYNalgAQ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_step(image, model, content_targets, style_targets, sum_writer, epoch):\n",
        "  with tf.GradientTape() as tape:\n",
        "    outputs = model(image)\n",
        "    loss = loss_cal(outputs, content_targets, style_targets)\n",
        "\n",
        "  gradients = tape.gradient(loss, image)\n",
        "  model.optimizer.apply_gradients([(gradients, image)])\n",
        "  image.assign(clip_img(image))\n",
        "  \n",
        "  with sum_writer.as_default():\n",
        "    tf.summary.scalar('Loss', loss, step=epoch)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_L-9C8m5ahI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NSTModel(tf.keras.Model):\n",
        "\n",
        "  def __init__(self, content_layers, style_layers):\n",
        "    super(NSTModel, self).__init__()\n",
        "    self.optimizer = tf.optimizers.Adam(learning_rate=0.001, beta_1=0.99, \n",
        "                                        epsilon=1e-1)\n",
        "    self.model = create_model(content_layers + style_layers)\n",
        "    self.preprocessor = tf.keras.applications.vgg19.preprocess_input\n",
        "    self.content_layers = content_layers\n",
        "    self.style_layers = style_layers\n",
        "    self.n_content_layers = len(content_layers)\n",
        "\n",
        "  def call(self, inputs):\n",
        "    inputs = inputs * 255.0\n",
        "    processed_inputs = self.preprocessor(inputs)\n",
        "    outputs = self.model(processed_inputs)\n",
        "    content_outputs, style_outputs = outputs[:self.n_content_layers], \\\n",
        "                                      outputs[self.n_content_layers:]\n",
        "    style_corr_values = [self._gram_matrix(feature_map) \n",
        "                        for feature_map in style_outputs]\n",
        "    content_map = {layer_name: layer_output for layer_name, layer_output \n",
        "                   in zip(self.content_layers, content_outputs)}\n",
        "    style_map = {layer_name: layer_output for layer_name, layer_output\n",
        "                 in zip(self.style_layers, style_corr_values)}\n",
        "    return {\"content_map\": content_map, \"style_map\": style_map}\n",
        "\n",
        "  def _gram_matrix(self, feature_map):\n",
        "    b, h, w, c = feature_map.shape\n",
        "    normalization_factor = tf.cast(h * w, dtype=tf.float32)\n",
        "    gram_matrix = tf.linalg.einsum('bijc,bijd->bcd', feature_map, feature_map, \n",
        "                                  name=\"gram_matrix\")\n",
        "    return gram_matrix / normalization_factor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZT-HfJdYTQ7",
        "colab_type": "text"
      },
      "source": [
        "# Content & Style Layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5RURqZoz7bA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Choosing our content layers\n",
        "content_layers = [\"block5_conv2\"]\n",
        "\n",
        "# Choosing out style layers\n",
        "style_layers = [\"block1_conv1\", \"block2_conv1\", \"block3_conv1\", \"block4_conv1\", \n",
        "                \"block5_conv1\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M2qHCEgdWYvO",
        "colab_type": "text"
      },
      "source": [
        "# Style Transfer Begins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "THq_MyGqWN2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating object for our model\n",
        "model = NSTModel(content_layers, style_layers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OVf7dvXjE6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loading our content image\n",
        "content_img = prepare_img(\"bhai.jpeg\")\n",
        "\n",
        "# Loading our style image\n",
        "style_img = prepare_img(\"style.jpg\")\n",
        "\n",
        "# Preparing our output image\n",
        "output_img = tf.Variable(content_img)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4XkQZD_FYpgN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing our target content values\n",
        "content_targets = model(content_img)[\"content_map\"]\n",
        "\n",
        "# Preparing our target style values\n",
        "style_targets = model(style_img)[\"style_map\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZ3zvX155yOJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Preparing tensorboad for visualization\n",
        "log_dir = \"logs/\"\n",
        "summary_writer = tf.summary.create_file_writer(\n",
        "    log_dir + \"fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {log_dir}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVI6lRcOZ5z6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Running gradient descent on output image\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "  train_step(output_img, model, content_targets, style_targets, \n",
        "                    summary_writer, epoch)\n",
        "  if epoch % 200 == 0:\n",
        "    show_result(output_img, True)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}